{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a6a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dropout, Dense, Flatten, Activation, Conv2D, MaxPool2D, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b6aad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('MNIST_data/train.csv')\n",
    "test = pd.read_csv('MNIST_data/test.csv')\n",
    "label = train.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cada321d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dimension: (42000, 784)\n",
      "test dimension: (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"train dimension:\", train.shape)\n",
    "print(\"test dimension:\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bba8f5",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ebb7f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#전처리 클래스 생성\n",
    "class PreprocessData:\n",
    "    def __init__(self, valid_size, random_state, scaling=False):\n",
    "        self.valid_size = valid_size\n",
    "        self.random_state = random_state\n",
    "        self.scaling = scaling\n",
    "    def load_datasets(self):\n",
    "        (train_images, train_labels), (test_images,test_labels) = cifar10.load_data()\n",
    "        \n",
    "    def scaled_pixels(self,images,labels):\n",
    "        if self.scaling: #scaling이 True일 경우\n",
    "            images = np.array(images / 255.0, dtype=np.float32)\n",
    "        else:\n",
    "            images = np.array(images,dtype=np.float32)\n",
    "        labels = np.array(labels, dtype=np.float32)\n",
    "        return images, labels\n",
    "    \n",
    "    def transform_ohe(self,labels):\n",
    "        ohe_labels = to_categorical(labels)\n",
    "        return ohe_labels\n",
    "    \n",
    "    def split_train_valid(self,train_images, train_ohe_labels,train_labels): #훈련데이터에서 검증데이터 추출\n",
    "        tr_images, val_images, tr_ohe_labels, val_ohe_labels,tr_labels,val_labels = train_test_split(train_images,\n",
    "                                                                               train_ohe_labels,train_labels, test_size=self.valid_size,\n",
    "                                                                               random_state = self.random_state)\n",
    "        return tr_images, val_images, tr_ohe_labels, val_ohe_labels, tr_labels,val_labels\n",
    "    def preprocess_data(self):\n",
    "        train_images,train_labels,test_images = train, label, test\n",
    "        \n",
    "        train_images, train_labels = self.scaled_pixels(train_images,train_labels)\n",
    "        \n",
    "        \n",
    "        train_ohe_labels = self.transform_ohe(train_labels)\n",
    "        \n",
    "        \n",
    "        tr_images,  val_images, tr_ohe_labels, val_ohe_labels ,tr_labels,val_labels = self.split_train_valid(train_images,train_ohe_labels,train_labels)\n",
    "        \n",
    "        \n",
    "        tr_images = tr_images.reshape(-1,28,28,1)\n",
    "        val_images = val_images.reshape(-1,28,28,1)\n",
    "        test_images = test_images.values.reshape(-1,28,28,1)\n",
    "        print('Train:' ,tr_images.shape,tr_labels.shape, tr_ohe_labels.shape)\n",
    "        print('Valid:', val_images.shape, val_ohe_labels.shape)\n",
    "        print('Test:' ,test_images.shape)\n",
    "        print\n",
    "        return tr_images, tr_ohe_labels, val_images, val_ohe_labels, test_images,tr_labels,val_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0037e26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (29400, 28, 28, 1) (29400,) (29400, 10)\n",
      "Valid: (12600, 28, 28, 1) (12600, 10)\n",
      "Test: (28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "tr_images, tr_ohe_labels, val_images, val_ohe_labels, test_images,tr_labels,val_labels  = PreprocessData(0.3,42,scaling=True).preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119807f2",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "99516e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_acc', patience=1)\n",
    "model.fit(x_train, to_categorical(Y_train), batch_size = 128, nb_epoch=100, verbose = 2, validation_split = .2)\n",
    "yPred = model.predict_classes(x_valid,batch_size=32,verbose=1)\n",
    "np.savetxt('mnist_output.csv', np.c_[range(1,len(yPred)+1),yPred], delimiter=',', header = 'ImageId,Label', comments = '', fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f109fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Modeling 클래스 생성\n",
    "class CnnModel:\n",
    "    input_size = 32\n",
    "    @classmethod\n",
    "    def change_input_size(cls,input_size):\n",
    "        CnnModel.input_size = input_size\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_model(verbose=True):\n",
    "        size = CnnModel.input_size\n",
    "        input_tensor = Input(shape=(size,size,1)) #왜 3차원인지 생각해보자   \n",
    "        x = Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal', activation='relu')(\n",
    "                    input_tensor)\n",
    "        x = Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "        x = Conv2D(filters=64, kernel_size=3, padding='same',kernel_initializer='he_normal',activation='relu')(x)\n",
    "        x = Conv2D(filters=64, kernel_size=3, padding='same',kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "        x = Conv2D(filters=128, kernel_size=3, padding='valid', kernel_initializer='he_normal',activation='relu')(x)\n",
    "        x = Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "        x = Conv2D(filters=256, kernel_size=3, strides=2, padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        x = Dropout(rate=0.4)(x)\n",
    "        x = Dense(units=256, kernel_initializer='he_normal', activation='relu')(x)\n",
    "        x = Dropout(rate=0.3)(x)\n",
    "        x = Dense(units=64, kernel_initializer='he_normal', activation='relu')(x)\n",
    "        output = Dense(units=10, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=input_tensor, outputs=output)\n",
    "\n",
    "        if verbose:\n",
    "            model.summary()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2e13f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "CnnModel.change_input_size(input_size=28)\n",
    "print(CnnModel().input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6901d94",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 28, 28, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 5, 5, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 5, 5, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 5, 5, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 5, 5, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 1, 1, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 1, 1, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 666,410\n",
      "Trainable params: 665,450\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CnnModel.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40a38ef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "919/919 [==============================] - 229s 246ms/step - loss: 0.0512 - accuracy: 0.9861 - val_loss: 0.0399 - val_accuracy: 0.9896\n",
      "Epoch 2/3\n",
      "919/919 [==============================] - 210s 229ms/step - loss: 0.0429 - accuracy: 0.9871 - val_loss: 0.0434 - val_accuracy: 0.9887\n",
      "Epoch 3/3\n",
      "919/919 [==============================] - 229s 249ms/step - loss: 0.0362 - accuracy: 0.9902 - val_loss: 0.0512 - val_accuracy: 0.9872\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])\n",
    "history=model.fit(tr_images,tr_labels,epochs=3,validation_data=(val_images, val_labels),\n",
    "                  batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "517ce6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 50s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(test_images), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43874854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394/394 - 18s - loss: 0.0512 - accuracy: 0.9872 - 18s/epoch - 45ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Access Model\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(val_images,  val_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65239078",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'ImageId': np.arange(1, 28001), 'Label': predictions})\n",
    "submission.to_csv('submission_modelB_tuning.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4706f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습데이터 보충을 위한 데이터 추가 생성\n",
    "#학습 과정 중 완전히 일치하는 동일 데이터를 못보게 하는 원리\n",
    "datagen  = ImageDataGenerator(rotation_range=10,horizontal_flip=True,\n",
    "                             zoom_range = 0.1,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1)\n",
    "datagen.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a3fafd28",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageDataGenerator' object has no attribute 'fit_generate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15216/3423974325.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'ImageDataGenerator' object has no attribute 'fit_generate'"
     ]
    }
   ],
   "source": [
    "datagen.fit_generate(train1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
